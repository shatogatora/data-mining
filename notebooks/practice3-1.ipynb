{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9957088b-d1de-48d5-a115-24e32c46ead5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: No matching packages\u001b[0m\u001b[33m\n",
      "\u001b[0mFiles removed: 0\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (2.0.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (3.9.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (1.14.1)\n",
      "Requirement already satisfied: statsmodels in /opt/conda/lib/python3.11/site-packages (0.14.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (1.5.1)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /opt/conda/lib/python3.11/site-packages (from statsmodels) (0.5.6)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from tensorflow) (73.0.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.68.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (3.11.0)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.5)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.4/615.4 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading wordcloud-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (547 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.9/547.9 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.68.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading wrapt-1.17.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (391 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, optree, opt-einsum, ml-dtypes, mdurl, markdown, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, markdown-it-py, wordcloud, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.68.1 keras-3.7.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.13.1 rich-13.9.4 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.5.0 werkzeug-3.1.3 wordcloud-1.9.4 wrapt-1.17.0\n",
      "\u001b[33mWARNING: Skipping spacy as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping ginza as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping ja_ginza as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting spacy==3.0\n",
      "  Downloading spacy-3.0.0.tar.gz (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[167 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m     int length\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m cdef class Vocab:\n",
      "  \u001b[31m   \u001b[0m     cdef Pool mem\n",
      "  \u001b[31m   \u001b[0m     cpdef readonly StringStore strings\n",
      "  \u001b[31m   \u001b[0m           ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m spacy/vocab.pxd:28:10: Variables cannot be declared with 'cpdef'. Use 'cdef' instead.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m cdef class Vocab:\n",
      "  \u001b[31m   \u001b[0m     cdef Pool mem\n",
      "  \u001b[31m   \u001b[0m     cpdef readonly StringStore strings\n",
      "  \u001b[31m   \u001b[0m     cpdef public Morphology morphology\n",
      "  \u001b[31m   \u001b[0m           ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m spacy/vocab.pxd:29:10: Variables cannot be declared with 'cpdef'. Use 'cdef' instead.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m cdef class Vocab:\n",
      "  \u001b[31m   \u001b[0m     cdef Pool mem\n",
      "  \u001b[31m   \u001b[0m     cpdef readonly StringStore strings\n",
      "  \u001b[31m   \u001b[0m     cpdef public Morphology morphology\n",
      "  \u001b[31m   \u001b[0m     cpdef public object vectors\n",
      "  \u001b[31m   \u001b[0m           ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m spacy/vocab.pxd:30:10: Variables cannot be declared with 'cpdef'. Use 'cdef' instead.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m cdef class Vocab:\n",
      "  \u001b[31m   \u001b[0m     cdef Pool mem\n",
      "  \u001b[31m   \u001b[0m     cpdef readonly StringStore strings\n",
      "  \u001b[31m   \u001b[0m     cpdef public Morphology morphology\n",
      "  \u001b[31m   \u001b[0m     cpdef public object vectors\n",
      "  \u001b[31m   \u001b[0m     cpdef public object _lookups\n",
      "  \u001b[31m   \u001b[0m           ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m spacy/vocab.pxd:31:10: Variables cannot be declared with 'cpdef'. Use 'cdef' instead.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m     cdef Pool mem\n",
      "  \u001b[31m   \u001b[0m     cpdef readonly StringStore strings\n",
      "  \u001b[31m   \u001b[0m     cpdef public Morphology morphology\n",
      "  \u001b[31m   \u001b[0m     cpdef public object vectors\n",
      "  \u001b[31m   \u001b[0m     cpdef public object _lookups\n",
      "  \u001b[31m   \u001b[0m     cpdef public object writing_system\n",
      "  \u001b[31m   \u001b[0m           ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m spacy/vocab.pxd:32:10: Variables cannot be declared with 'cpdef'. Use 'cdef' instead.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m     cpdef readonly StringStore strings\n",
      "  \u001b[31m   \u001b[0m     cpdef public Morphology morphology\n",
      "  \u001b[31m   \u001b[0m     cpdef public object vectors\n",
      "  \u001b[31m   \u001b[0m     cpdef public object _lookups\n",
      "  \u001b[31m   \u001b[0m     cpdef public object writing_system\n",
      "  \u001b[31m   \u001b[0m     cpdef public object get_noun_chunks\n",
      "  \u001b[31m   \u001b[0m           ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m spacy/vocab.pxd:33:10: Variables cannot be declared with 'cpdef'. Use 'cdef' instead.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m     cdef float prior_prob\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m cdef class KnowledgeBase:\n",
      "  \u001b[31m   \u001b[0m     cdef Pool mem\n",
      "  \u001b[31m   \u001b[0m     cpdef readonly Vocab vocab\n",
      "  \u001b[31m   \u001b[0m           ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m spacy/kb.pxd:31:10: Variables cannot be declared with 'cpdef'. Use 'cdef' instead.\n",
      "  \u001b[31m   \u001b[0m Copied /tmp/pip-install-e3p02htg/spacy_dec78360812e4289add6c09a91d57adf/setup.cfg -> /tmp/pip-install-e3p02htg/spacy_dec78360812e4289add6c09a91d57adf/spacy/tests/package\n",
      "  \u001b[31m   \u001b[0m Copied /tmp/pip-install-e3p02htg/spacy_dec78360812e4289add6c09a91d57adf/pyproject.toml -> /tmp/pip-install-e3p02htg/spacy_dec78360812e4289add6c09a91d57adf/spacy/tests/package\n",
      "  \u001b[31m   \u001b[0m Cythonizing sources\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/training/example.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/parts_of_speech.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/strings.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/lexeme.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/vocab.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/attrs.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/kb.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/ml/parser_model.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/morphology.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/pipeline/dep_parser.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/pipeline/morphologizer.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/pipeline/multitask.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/pipeline/ner.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/pipeline/pipe.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/pipeline/trainable_pipe.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/pipeline/sentencizer.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/pipeline/senter.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/pipeline/tagger.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/pipeline/transition_parser.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/pipeline/_parser_internals/arc_eager.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/pipeline/_parser_internals/ner.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/pipeline/_parser_internals/nonproj.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/pipeline/_parser_internals/_state.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/pipeline/_parser_internals/stateclass.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/pipeline/_parser_internals/transition_system.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/pipeline/_parser_internals/_beam_utils.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/tokenizer.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/training/align.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/training/gold_io.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/tokens/doc.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/tokens/span.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/tokens/token.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/tokens/span_group.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/tokens/graph.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/tokens/morphanalysis.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/tokens/_retokenize.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/matcher/matcher.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/matcher/phrasematcher.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/matcher/dependencymatcher.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/symbols.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling spacy/vectors.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m [ 1/41] Cythonizing spacy/attrs.pyx\n",
      "  \u001b[31m   \u001b[0m [ 2/41] Cythonizing spacy/kb.pyx\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.11/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 353, in <module>\n",
      "  \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.11/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 335, in main\n",
      "  \u001b[31m   \u001b[0m     json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "  \u001b[31m   \u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.11/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return hook(config_settings)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-0k4bse0q/overlay/lib/python3.11/site-packages/setuptools/build_meta.py\", line 334, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return self._get_build_requires(config_settings, requirements=[])\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-0k4bse0q/overlay/lib/python3.11/site-packages/setuptools/build_meta.py\", line 304, in _get_build_requires\n",
      "  \u001b[31m   \u001b[0m     self.run_setup()\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-0k4bse0q/overlay/lib/python3.11/site-packages/setuptools/build_meta.py\", line 320, in run_setup\n",
      "  \u001b[31m   \u001b[0m     exec(code, locals())\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 225, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 211, in setup_package\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-0k4bse0q/overlay/lib/python3.11/site-packages/Cython/Build/Dependencies.py\", line 1154, in cythonize\n",
      "  \u001b[31m   \u001b[0m     cythonize_one(*args)\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-0k4bse0q/overlay/lib/python3.11/site-packages/Cython/Build/Dependencies.py\", line 1321, in cythonize_one\n",
      "  \u001b[31m   \u001b[0m     raise CompileError(None, pyx_file)\n",
      "  \u001b[31m   \u001b[0m Cython.Compiler.Errors.CompileError: spacy/kb.pyx\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25hCollecting ginza\n",
      "  Downloading ginza-5.2.0-py3-none-any.whl.metadata (448 bytes)\n",
      "Collecting spacy<4.0.0,>=3.4.4 (from ginza)\n",
      "  Downloading spacy-3.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
      "Collecting plac>=1.3.3 (from ginza)\n",
      "  Downloading plac-1.4.3-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting SudachiPy<0.7.0,>=0.6.2 (from ginza)\n",
      "  Downloading SudachiPy-0.6.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting SudachiDict-core>=20210802 (from ginza)\n",
      "  Downloading SudachiDict_core-20241021-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Using cached murmurhash-1.0.11-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Using cached cymem-2.0.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Using cached preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.0 (from spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading thinc-8.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Using cached srsly-2.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Using cached typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (73.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (24.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (2.0.2)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->ginza) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->ginza) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->ginza) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ginza) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ginza) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ginza) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ginza) (2024.8.30)\n",
      "Collecting blis<1.1.0,>=1.0.0 (from thinc<8.4.0,>=8.3.0->spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading blis-1.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.0->spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ginza) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ginza) (13.9.4)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading cloudpathlib-0.20.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading smart_open-7.0.5-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->spacy<4.0.0,>=3.4.4->ginza) (2.1.5)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading marisa_trie-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ginza) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ginza) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->ginza) (1.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ginza) (0.1.2)\n",
      "Downloading ginza-5.2.0-py3-none-any.whl (21 kB)\n",
      "Downloading plac-1.4.3-py2.py3-none-any.whl (22 kB)\n",
      "Downloading spacy-3.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading SudachiDict_core-20241021-py3-none-any.whl (72.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.1/72.1 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading SudachiPy-0.6.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Using cached cymem-2.0.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (218 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Using cached murmurhash-1.0.11-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (134 kB)\n",
      "Using cached preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Using cached srsly-2.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (490 kB)\n",
      "Downloading thinc-8.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Downloading blis-1.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloudpathlib-0.20.0-py3-none-any.whl (52 kB)\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading smart_open-7.0.5-py3-none-any.whl (61 kB)\n",
      "Downloading marisa_trie-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: SudachiPy, plac, cymem, wasabi, SudachiDict-core, spacy-loggers, spacy-legacy, smart-open, shellingham, murmurhash, marisa-trie, cloudpathlib, catalogue, blis, srsly, preshed, language-data, typer, langcodes, confection, weasel, thinc, spacy, ginza\n",
      "Successfully installed SudachiDict-core-20241021 SudachiPy-0.6.9 blis-1.0.1 catalogue-2.0.10 cloudpathlib-0.20.0 confection-0.1.5 cymem-2.0.10 ginza-5.2.0 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 murmurhash-1.0.11 plac-1.4.3 preshed-3.0.9 shellingham-1.5.4 smart-open-7.0.5 spacy-3.8.2 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.3.2 typer-0.15.1 wasabi-1.1.3 weasel-0.4.1\n",
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.11/site-packages (3.8.2)\n",
      "Requirement already satisfied: ginza in /opt/conda/lib/python3.11/site-packages (5.2.0)\n",
      "Collecting ja_ginza\n",
      "  Downloading ja_ginza-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (1.0.11)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.11/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.11/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (8.3.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.11/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.11/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.11/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (0.15.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.11/site-packages (from spacy) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from spacy) (73.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (2.0.2)\n",
      "Requirement already satisfied: plac>=1.3.3 in /opt/conda/lib/python3.11/site-packages (from ginza) (1.4.3)\n",
      "Requirement already satisfied: SudachiPy<0.7.0,>=0.6.2 in /opt/conda/lib/python3.11/site-packages (from ginza) (0.6.9)\n",
      "Requirement already satisfied: SudachiDict-core>=20210802 in /opt/conda/lib/python3.11/site-packages (from ginza) (20241021)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<1.1.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from thinc<8.4.0,>=8.3.0->spacy) (1.0.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.11/site-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Downloading ja_ginza-5.2.0-py3-none-any.whl (59.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ja_ginza\n",
      "Successfully installed ja_ginza-5.2.0\n",
      "Collecting chardet\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Installing collected packages: chardet\n",
      "Successfully installed chardet-5.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip cache purge\n",
    "!pip install numpy pandas matplotlib scipy statsmodels scikit-learn tensorflow wordcloud\n",
    "\n",
    "# spaCyとginzaをアンインストール\n",
    "!pip uninstall -y spacy ginza ja_ginza\n",
    "\n",
    "# 必要なバージョンを再インストール\n",
    "!pip install spacy==3.0\n",
    "!pip install ginza\n",
    "!pip install --no-cache-dir spacy ginza ja_ginza\n",
    "\n",
    "!pip install chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c42da16-cf36-401c-a2f2-3d0ec4425cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dcd96bb-1534-417c-9598-c6bb4fc9ee12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "スレッドタイトルの総件数: 100000\n"
     ]
    }
   ],
   "source": [
    "#q1-1\n",
    "import csv\n",
    "# ファイルを読み込む\n",
    "file_path = \"../data/practice3-1/testset100k.txt\"\n",
    "\n",
    "# タイトル抽出リスト\n",
    "thread_titles = []\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    reader = csv.reader(file, delimiter=\"\\t\")  # タブ区切りで読み込み\n",
    "    for row in reader:\n",
    "        # タイトル（3番目の列）を取得\n",
    "        if len(row) > 2:  # カラムが正しく存在するかチェック\n",
    "            title = row[2].strip()  # タイトルを取得\n",
    "            thread_titles.append(title)\n",
    "\n",
    "# 件数をカウント\n",
    "thread_count = len(thread_titles)\n",
    "\n",
    "# 結果表示\n",
    "print(f\"スレッドタイトルの総件数: {thread_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54f6d09c-b701-4aa2-bf7e-61613673f270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ユニーク名詞数: 39562\n"
     ]
    }
   ],
   "source": [
    "#q1-2\n",
    "import csv\n",
    "import spacy\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "# giNZAのロード（パイプラインの一部を無効化して高速化）\n",
    "nlp = spacy.load(\"ja_ginza\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "# ファイルパスを指定\n",
    "file_path = \"../data/practice3-1/testset100k.txt\"\n",
    "\n",
    "# 名詞を格納するセット（重複を除くためセットを使用）\n",
    "unique_nouns = set()\n",
    "\n",
    "# タイトルから名詞を抽出する関数\n",
    "def extract_nouns(title):\n",
    "    doc = nlp(title)\n",
    "    return {token.text for token in doc if token.pos_ == \"NOUN\"}\n",
    "\n",
    "# ファイルを読み込み、並列でスレッドタイトルを抽出\n",
    "def process_file(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        reader = csv.reader(file, delimiter=\"\\t\")  # タブ区切りで読み込み\n",
    "        titles = [row[2].strip() for row in reader if len(row) > 2]  # スレッドタイトルを抽出\n",
    "    return titles\n",
    "\n",
    "# 並列処理を使って名詞を抽出\n",
    "def parallel_extract(file_path):\n",
    "    # ファイルから並列でスレッドタイトルを抽出\n",
    "    titles = process_file(file_path) # 自分で定義した関数\n",
    "\n",
    "    # プロセスプールを使って並列処理\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        # titles各要素から名詞を抽出\n",
    "        results = executor.map(extract_nouns, titles) # titlesリストの要素に対して並列にextract_nounsを実行\n",
    "\n",
    "    # 各プロセスで得られた名詞をユニークに統合\n",
    "    for result in results:\n",
    "        unique_nouns.update(result)\n",
    "\n",
    "# 並列処理で名詞抽出を実行\n",
    "parallel_extract(file_path)\n",
    "\n",
    "# ユニーク名詞の件数\n",
    "unique_noun_count = len(unique_nouns)\n",
    "\n",
    "# 結果を表示\n",
    "print(f\"ユニーク名詞数: {unique_noun_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "969616b4-6239-42a1-9c3a-053fc67bca76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01:\n",
      "  さん: 383\n",
      "  ら: 371\n",
      "  人: 354\n",
      "  スレ: 319\n",
      "  こと: 288\n",
      "  女: 254\n",
      "  お: 236\n",
      "  奴: 221\n",
      "  ちゃん: 219\n",
      "  悲報: 202\n",
      "2020-02:\n",
      "  人: 373\n",
      "  ら: 368\n",
      "  さん: 354\n",
      "  コロナ: 311\n",
      "  こと: 288\n",
      "  スレ: 287\n",
      "  悲報: 225\n",
      "  ちゃん: 218\n",
      "  奴: 211\n",
      "  画像: 207\n",
      "2020-03:\n",
      "  コロナ: 540\n",
      "  人: 534\n",
      "  さん: 423\n",
      "  ら: 408\n",
      "  スレ: 342\n",
      "  こと: 334\n",
      "  日: 265\n",
      "  お: 258\n",
      "  悲報: 245\n",
      "  奴: 243\n",
      "2020-04:\n",
      "  コロナ: 757\n",
      "  人: 508\n",
      "  ら: 443\n",
      "  さん: 421\n",
      "  こと: 354\n",
      "  スレ: 317\n",
      "  悲報: 316\n",
      "  円: 305\n",
      "  ちゃん: 253\n",
      "  マスク: 250\n",
      "2020-05:\n",
      "  ら: 488\n",
      "  人: 414\n",
      "  さん: 409\n",
      "  コロナ: 347\n",
      "  こと: 318\n",
      "  スレ: 302\n",
      "  女: 266\n",
      "  奴: 265\n",
      "  ちゃん: 264\n",
      "  画像: 261\n",
      "2020-06:\n",
      "  さん: 296\n",
      "  人: 289\n",
      "  ら: 288\n",
      "  こと: 248\n",
      "  スレ: 222\n",
      "  悲報: 189\n",
      "  円: 182\n",
      "  女: 181\n",
      "  画像: 180\n",
      "  ちゃん: 176\n",
      "2020-07:\n",
      "  人: 446\n",
      "  さん: 422\n",
      "  ら: 378\n",
      "  スレ: 294\n",
      "  こと: 285\n",
      "  悲報: 271\n",
      "  お: 254\n",
      "  画像: 247\n",
      "  女: 231\n",
      "  コロナ: 230\n",
      "2020-08:\n",
      "  さん: 417\n",
      "  ら: 405\n",
      "  人: 387\n",
      "  こと: 309\n",
      "  スレ: 290\n",
      "  画像: 264\n",
      "  お: 256\n",
      "  女: 245\n",
      "  ちゃん: 239\n",
      "  悲報: 207\n",
      "2020-09:\n",
      "  さん: 400\n",
      "  ら: 398\n",
      "  人: 317\n",
      "  こと: 298\n",
      "  スレ: 265\n",
      "  画像: 257\n",
      "  女: 232\n",
      "  悲報: 226\n",
      "  お: 222\n",
      "  ちゃん: 218\n",
      "2020-10:\n",
      "  ら: 271\n",
      "  さん: 268\n",
      "  人: 207\n",
      "  スレ: 188\n",
      "  画像: 174\n",
      "  こと: 173\n",
      "  ちゃん: 158\n",
      "  お: 150\n",
      "  女: 144\n",
      "  悲報: 128\n",
      "2021-04:\n",
      "  スレ: 60\n",
      "  Part: 32\n",
      "  総合: 18\n",
      "  人: 16\n",
      "  年: 14\n",
      "  目: 14\n",
      "  part: 12\n",
      "  情報: 10\n",
      "  板: 9\n",
      "  PS: 9\n"
     ]
    }
   ],
   "source": [
    "#q1-3\n",
    "import csv\n",
    "from collections import defaultdict, Counter\n",
    "import spacy\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "nlp = spacy.load(\"ja_ginza\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "file_path = \"../data/practice3-1/testset100k.txt\"\n",
    "\n",
    "# 月ごとのキーワードを処理する関数\n",
    "def process_monthly_keywords(args):\n",
    "    month_key, titles = args\n",
    "    keywords = []\n",
    "    for title in titles:\n",
    "        doc = nlp(title)\n",
    "        nouns = [token.text for token in doc if token.pos_ == \"NOUN\"]\n",
    "        keywords.extend(nouns)\n",
    "    # キーワードの出現数をカウントし、上位10件を取得\n",
    "    keyword_counts = Counter(keywords)\n",
    "    return month_key, keyword_counts.most_common(10)\n",
    "\n",
    "# メイン処理\n",
    "def main(file_path):\n",
    "    monthly_titles = defaultdict(list)  # 月ごとのタイトルリスト\n",
    "\n",
    "    # ファイルを読み込み、月別にタイトルを整理\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        reader = csv.reader(file, delimiter=\"\\t\")  # タブ区切りで読み込み\n",
    "        for row in reader:\n",
    "            if len(row) > 2:  # スレッドタイトルと日時が存在するかチェック\n",
    "                title = row[2].strip()  # スレッドタイトルを取得\n",
    "                date_str = row[5].strip()  # 投稿日時を取得\n",
    "                try:\n",
    "                    # 日時をdatetimeに変換\n",
    "                    post_date = datetime.strptime(date_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "                    month_key = post_date.strftime(\"%Y-%m\")  # 年月キー（例: \"2020-02\"）\n",
    "                    monthly_titles[month_key].append(title)\n",
    "                except ValueError:\n",
    "                    # 無効な日時データをスキップ\n",
    "                    continue\n",
    "\n",
    "    # 並列処理を実行\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        results = executor.map(process_monthly_keywords, monthly_titles.items())\n",
    "\n",
    "    # 結果を辞書にまとめる\n",
    "    top_keywords_per_month = dict(results)\n",
    "\n",
    "    # 結果を表示\n",
    "    for month, top_keywords in sorted(top_keywords_per_month.items()):\n",
    "        print(f\"{month}:\")\n",
    "        for keyword, count in top_keywords:\n",
    "            print(f\"  {keyword}: {count}\")\n",
    "\n",
    "# 実行\n",
    "if __name__ == \"__main__\":\n",
    "    main(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c004ee71-267b-4c36-ae15-e59b9b52a100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01:\n",
      "  お年玉: 0.92\n",
      "  新年: 0.92\n",
      "  新春: 0.89\n",
      "  落: 0.89\n",
      "  財閥: 0.89\n",
      "  縦読み: 0.86\n",
      "  元日: 0.86\n",
      "  成人式: 0.83\n",
      "  ゴーン: 0.82\n",
      "  DASADA: 0.80\n",
      "2020-02:\n",
      "  恵方: 0.93\n",
      "  ケイジ: 0.88\n",
      "  バレンタインデー: 0.86\n",
      "  サツマイモ: 0.86\n",
      "  バレンタイン: 0.85\n",
      "  ガチムチ: 0.83\n",
      "  探検: 0.83\n",
      "  混浴: 0.80\n",
      "  ふたり: 0.80\n",
      "  失格: 0.80\n",
      "2020-03:\n",
      "  お祝い: 0.88\n",
      "  円高: 0.88\n",
      "  花見: 0.88\n",
      "  ｱ: 0.86\n",
      "  ﾞ: 0.86\n",
      "  商品券: 0.85\n",
      "  体験版: 0.83\n",
      "  オーバーシュート: 0.83\n",
      "  入国者: 0.83\n",
      "  特措法: 0.80\n",
      "2020-04:\n",
      "  BCG: 0.89\n",
      "  ホットライン: 0.84\n",
      "  一律: 0.84\n",
      "  不良品: 0.83\n",
      "  ホッ: 0.83\n",
      "  協力者: 0.83\n",
      "  減便: 0.83\n",
      "  小人: 0.80\n",
      "  半減: 0.80\n",
      "  こめ: 0.80\n",
      "2020-05:\n",
      "  マージャン: 0.92\n",
      "  チミル: 0.91\n",
      "  まき: 0.90\n",
      "  法改正: 0.84\n",
      "  オークス: 0.83\n",
      "  アパホテル: 0.80\n",
      "  検事長: 0.80\n",
      "  コメンテーター: 0.80\n",
      "  オンライン申請: 0.80\n",
      "  総長: 0.80\n",
      "2020-06:\n",
      "  帰れ: 0.88\n",
      "  手越: 0.83\n",
      "  激励: 0.75\n",
      "  腹黒: 0.75\n",
      "  公約: 0.75\n",
      "  すけ: 0.75\n",
      "  交付金: 0.75\n",
      "  アンインストール: 0.75\n",
      "  Blu-ray: 0.75\n",
      "  略奪: 0.75\n",
      "2020-07:\n",
      "  氾濫: 0.88\n",
      "  びえ: 0.86\n",
      "  プラエデ: 0.83\n",
      "  両立: 0.83\n",
      "  区民: 0.83\n",
      "  To: 0.82\n",
      "  ロマン: 0.80\n",
      "  水位: 0.80\n",
      "  土用: 0.80\n",
      "  ∪: 0.75\n",
      "2020-08:\n",
      "  イソジン: 0.89\n",
      "  盆休み: 0.88\n",
      "  うがい薬: 0.88\n",
      "  盆: 0.86\n",
      "  アクタージュ: 0.86\n",
      "  ドーパミン: 0.80\n",
      "  CL: 0.80\n",
      "  大腸炎: 0.80\n",
      "  しり: 0.80\n",
      "  うがい: 0.80\n",
      "2020-09:\n",
      "  hPa: 0.83\n",
      "  風速: 0.80\n",
      "  志士: 0.80\n",
      "  下敷き: 0.80\n",
      "  孫娘: 0.80\n",
      "  勝て: 0.80\n",
      "  石破: 0.75\n",
      "  ○: 0.75\n",
      "  置き去り: 0.75\n",
      "  ポット: 0.75\n",
      "2020-10:\n",
      "  学術: 0.93\n",
      "  ナナ: 0.86\n",
      "  ケトル: 0.80\n",
      "  任命: 0.79\n",
      "  墓場: 0.75\n",
      "  エディ: 0.75\n",
      "  オメコ: 0.75\n",
      "  Saki: 0.75\n",
      "  避妊薬: 0.75\n",
      "  せっかち: 0.75\n",
      "2021-04:\n",
      "  峯: 0.75\n",
      "  Update: 0.67\n",
      "  旺: 0.67\n",
      "  総本山: 0.60\n",
      "  DQX: 0.50\n",
      "  メトロ: 0.50\n",
      "  紫電: 0.50\n",
      "  学会員: 0.50\n",
      "  bbs: 0.50\n",
      "  DARK: 0.50\n"
     ]
    }
   ],
   "source": [
    "#q1-4\n",
    "\n",
    "import csv\n",
    "from collections import defaultdict, Counter\n",
    "import spacy\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "nlp = spacy.load(\"ja_ginza\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "file_path = \"../data/practice3-1/testset100k.txt\"\n",
    "\n",
    "monthly_keywords = defaultdict(list)  # 月ごとのキーワードリスト\n",
    "\n",
    "# ファイルを読み込み、月別にキーワードを抽出\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    reader = csv.reader(file, delimiter=\"\\t\")  # タブ区切りで読み込み\n",
    "    for row in reader:\n",
    "        if len(row) > 2:  # スレッドタイトルと日時が存在するかチェック\n",
    "            title = row[2].strip()  # スレッドタイトルを取得\n",
    "            date_str = row[5].strip()  # 投稿日時を取得\n",
    "\n",
    "            try:\n",
    "                # 日時をdatetimeに変換して月を取得\n",
    "                post_date = datetime.strptime(date_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "                month_key = post_date.strftime(\"%Y-%m\")  # 年月キー（例: \"2020-02\")\n",
    "\n",
    "                # GiNZAを用いて名詞を抽出\n",
    "                doc = nlp(title)\n",
    "                nouns = [token.text for token in doc if token.pos_ == \"NOUN\"]\n",
    "\n",
    "                # 月ごとのキーワードリストに追加\n",
    "                monthly_keywords[month_key].extend(nouns)\n",
    "            except ValueError:\n",
    "                # 無効な日付データをスキップ\n",
    "                continue\n",
    "\n",
    "# 全体の頻度を集計\n",
    "all_keywords = []  # 全体のキーワードリスト\n",
    "for keywords in monthly_keywords.values():  # values()でキーワードのみ取得\n",
    "    all_keywords.extend(keywords)\n",
    "\n",
    "total_keyword_counts = Counter(all_keywords)  # 全体の頻度を保持する辞書\n",
    "\n",
    "# 特徴語を抽出する関数\n",
    "def extract_characteristic_keywords(args):\n",
    "    month, keywords, total_keyword_counts = args\n",
    "    keyword_counts = Counter(keywords)  # 各月のキーワード頻度({\"猫\":2}のように格納)\n",
    "    characteristics = {}\n",
    "    for word, count in keyword_counts.items():\n",
    "        overall_ratio = count / total_keyword_counts[word]  # 全体頻度に対する割合\n",
    "        if 0.5 <= overall_ratio < 1.0:  # 全体頻度の 50% 以上を占めるが、100% ではない\n",
    "            characteristics[word] = overall_ratio\n",
    "    # 上位10件を抽出\n",
    "    sorted_characteristics = sorted(characteristics.items(), key=lambda x: x[1], reverse=True)\n",
    "    return month, sorted_characteristics[:10]\n",
    "\n",
    "# 並列処理で特徴語を抽出\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    results = executor.map(\n",
    "        extract_characteristic_keywords,  # 特徴語を抽出\n",
    "        [(month, keywords, total_keyword_counts) for month, keywords in monthly_keywords.items()]\n",
    "    )\n",
    "\n",
    "# 結果を辞書に格納\n",
    "top_keywords_per_month = dict(results)\n",
    "\n",
    "# 結果を表示\n",
    "for month, top_keywords in sorted(top_keywords_per_month.items()):\n",
    "    print(f\"{month}:\")\n",
    "    for keyword, ratio in top_keywords:\n",
    "        print(f\"  {keyword}: {ratio:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
